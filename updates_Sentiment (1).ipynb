{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zitHSssRCZdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "# Text cleaning function with option to remove emoticons\n",
        "def clean_text(text, remove_emoticons=True):\n",
        "    if isinstance(text, str):\n",
        "        if remove_emoticons:\n",
        "            text = re.sub(r'[^\\w\\s]', '', text)  # Remove emoticons\n",
        "        text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove non-alphabetical characters\n",
        "        text = text.lower()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in text.split() if word not in stop_words]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path, remove_emoticons=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[['review_description', 'rating']]\n",
        "    df['review_description'] = df['review_description'].astype(str)\n",
        "    df['cleaned_review'] = df['review_description'].apply(lambda x: clean_text(x, remove_emoticons))\n",
        "    df['sentiment'] = df['rating'].apply(label_sentiment)\n",
        "    return df\n",
        "\n",
        "# Function to label sentiment\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "# Function to create additional features\n",
        "def add_text_features(df):\n",
        "    # Adding length of review as a feature\n",
        "    df['review_length'] = df['cleaned_review'].apply(len)\n",
        "\n",
        "    # Adding word count as a feature\n",
        "    df['word_count'] = df['cleaned_review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Function to prepare data for sentiment analysis\n",
        "def prepare_data_for_sentiment(df):\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df['sentiment'])\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42), le, vectorizer\n",
        "\n",
        "# Function to train the sentiment analysis model\n",
        "def train_sentiment_model(X_train, y_train):\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Function to calculate aggregate sentiment score\n",
        "def calculate_sentiment_score(df, model, vectorizer, label_encoder):\n",
        "    X = vectorizer.transform(df['cleaned_review'])\n",
        "    y_pred = model.predict(X)\n",
        "    sentiment_scores = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "    # Convert sentiments to numeric scores\n",
        "    sentiment_numeric = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
        "    df['sentiment_score'] = [sentiment_numeric[sent] for sent in sentiment_scores]\n",
        "\n",
        "    # Calculate aggregate sentiment score\n",
        "    aggregate_sentiment_score = df['sentiment_score'].mean()\n",
        "    return aggregate_sentiment_score\n",
        "\n",
        "# Function to compare app rating with sentiment score\n",
        "def compare_rating_with_sentiment(df):\n",
        "    # Calculate the overall app rating\n",
        "    overall_rating = df['rating'].mean()\n",
        "\n",
        "    # Prepare data and train sentiment model\n",
        "    (X_train, X_test, y_train, y_test), label_encoder, vectorizer = prepare_data_for_sentiment(df)\n",
        "    sentiment_model = train_sentiment_model(X_train, y_train)\n",
        "\n",
        "    # Calculate aggregate sentiment score\n",
        "    aggregate_sentiment_score = calculate_sentiment_score(df, sentiment_model, vectorizer, label_encoder)\n",
        "\n",
        "    # Print the comparison\n",
        "    print(\"\\n--- App Rating vs. Sentiment Score ---\")\n",
        "    print(f\"Overall Numeric Rating: {overall_rating:.2f}\")\n",
        "    print(f\"Aggregate Sentiment Score: {aggregate_sentiment_score:.2f}\")\n",
        "\n",
        "    # Identify discrepancies\n",
        "    discrepancy = overall_rating - aggregate_sentiment_score\n",
        "    print(f\"\\nDiscrepancy between rating and sentiment score: {discrepancy:.2f}\")\n",
        "    if discrepancy > 0:\n",
        "        print(\"The numeric rating is higher than the sentiment score.\")\n",
        "    elif discrepancy < 0:\n",
        "        print(\"The sentiment score is higher than the numeric rating.\")\n",
        "    else:\n",
        "        print(\"The numeric rating and sentiment score are in agreement.\")\n",
        "\n",
        "    # Save insights to a CSV\n",
        "    df[['review_description', 'rating', 'sentiment_score']].to_csv('rating_sentiment_comparison.csv', index=False)\n",
        "    print(\"\\nThe comparison results have been saved to 'rating_sentiment_comparison.csv'.\")\n",
        "\n",
        "# Main function\n",
        "def main_comprehensive_insight(file_path):\n",
        "    # Load and preprocess data\n",
        "    df = load_and_preprocess_data(file_path, remove_emoticons=False)\n",
        "\n",
        "    # Add text features (optional, for future use)\n",
        "    df = add_text_features(df)\n",
        "\n",
        "    # Compare overall rating with sentiment score\n",
        "    compare_rating_with_sentiment(df)\n",
        "\n",
        "# Example usage\n",
        "main_comprehensive_insight('/content/fitbit (1).csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yInZpjKwCZa0",
        "outputId": "b1dce54a-8d75-47e8-ae6a-2bdedbec8d3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- App Rating vs. Sentiment Score ---\n",
            "Overall Numeric Rating: 3.29\n",
            "Aggregate Sentiment Score: 0.15\n",
            "\n",
            "Discrepancy between rating and sentiment score: 3.15\n",
            "The numeric rating is higher than the sentiment score.\n",
            "\n",
            "The comparison results have been saved to 'rating_sentiment_comparison.csv'.\n"
          ]
        }
      ]
    }
  ]
}