{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CamM7WqWsFI7",
        "outputId": "b5c7a863-5998-439f-ce2e-b63d4325549b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [19:36:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Table 9: Numeric-Rating Prediction using Ensemble Classifiers\n",
            "| Classifier   |   Predicted Rating |\n",
            "|:-------------|-------------------:|\n",
            "| XGB          |               4.56 |\n",
            "| RF           |               4.59 |\n",
            "| GBM          |               4.42 |\n",
            "| AB           |               4.47 |\n",
            "| ET           |               4.61 |\n",
            "\n",
            "Random Forest Results with Different VSM Techniques (Table 10):\n",
            "|    | VSM Technique   |   Accuracy |\n",
            "|---:|:----------------|-----------:|\n",
            "|  0 | TF/IDF          |     0.8171 |\n",
            "|  1 | TF/IDF(Bigram)  |     0.8166 |\n",
            "|  2 | TF/IDF(Trigram) |     0.8168 |\n",
            "|  3 | TF              |     0.8174 |\n",
            "\n",
            "Random Forest Results with and without Emoticons (Table 11):\n",
            "|    | VSM Technique            |   Accuracy |\n",
            "|---:|:-------------------------|-----------:|\n",
            "|  0 | TF/IDF with Emoticons    |     0.8171 |\n",
            "|  1 | TF/IDF without Emoticons |     0.8171 |\n",
            "\n",
            "Gradient Boosting Results with Different Learning Rates (Table 12):\n",
            "|    |   Learning Rate |   Accuracy |\n",
            "|---:|----------------:|-----------:|\n",
            "|  0 |          0.0500 |     0.7536 |\n",
            "|  1 |          0.1000 |     0.7752 |\n",
            "|  2 |          0.2500 |     0.7974 |\n",
            "|  3 |          0.5000 |     0.8077 |\n",
            "|  4 |          0.7500 |     0.8099 |\n",
            "|  5 |          1.0000 |     0.8114 |\n",
            "\n",
            "Results have been saved to 'numeric_rating_results.csv', 'rf_vsm_results.csv', 'rf_emoticon_results.csv', and 'gbm_learning_rate_results.csv'\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path, remove_emoticons=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[['review_description', 'rating']]\n",
        "    df['review_description'] = df['review_description'].astype(str)\n",
        "    df['cleaned_review'] = df['review_description'].apply(lambda x: clean_text(x, remove_emoticons))\n",
        "    df['sentiment'] = df['rating'].apply(label_sentiment)\n",
        "    return df\n",
        "\n",
        "# Text cleaning function with option to remove emoticons\n",
        "def clean_text(text, remove_emoticons=True):\n",
        "    if isinstance(text, str):\n",
        "        if remove_emoticons:\n",
        "            text = re.sub(r'[^\\w\\s]', '', text)  # Remove emoticons\n",
        "        text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove non-alphabetical characters\n",
        "        text = text.lower()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in text.split() if word not in stop_words]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Function to label sentiment\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "# Prepare data for modeling\n",
        "def prepare_data_for_modeling(df):\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df['sentiment'])\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest using different VSM techniques\n",
        "def train_rf_with_vsm_techniques(df):\n",
        "    results = []\n",
        "\n",
        "    # TF-IDF Unigram\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF-IDF Bigrams\n",
        "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF(Bigram)', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF-IDF Trigrams\n",
        "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF(Trigram)', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF (Term Frequency only)\n",
        "    vectorizer = CountVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF', 'Accuracy': accuracy})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Function to train Random Forest with and without emoticons\n",
        "def train_rf_with_emoticons(df_with_emoticons, df_without_emoticons):\n",
        "    results = []\n",
        "\n",
        "    # Run Random Forest with Emoticons\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df_with_emoticons['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df_with_emoticons['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF with Emoticons', 'Accuracy': accuracy})\n",
        "\n",
        "    # Run Random Forest without Emoticons\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df_without_emoticons['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df_without_emoticons['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF without Emoticons', 'Accuracy': accuracy})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Train Gradient Boosting models with different learning rates\n",
        "def train_gbm_with_different_learning_rates(X_train, X_test, y_train, y_test):\n",
        "    learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "    results = []\n",
        "    for rate in learning_rates:\n",
        "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=rate, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results.append({'Learning Rate': rate, 'Accuracy': accuracy})\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Function to generate Table 9: Numeric-Rating Prediction using Ensemble Classifiers\n",
        "def numeric_rating_prediction(df):\n",
        "    classifiers = {\n",
        "        'XGB': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "        'RF': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'GBM': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "        'AB': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
        "        'ET': ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        X_train, X_test, y_train, y_test = prepare_data_for_modeling(df)\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        rating = 5 - mse  # Example of numeric rating conversion\n",
        "        results.append({'Classifier': name, 'Predicted Rating': f\"{rating:.2f}\"})\n",
        "\n",
        "    # Display the table\n",
        "    table_df = pd.DataFrame(results)\n",
        "    print(\"\\nTable 9: Numeric-Rating Prediction using Ensemble Classifiers\")\n",
        "    print(tabulate(table_df, headers='keys', tablefmt='pipe', showindex=False))\n",
        "\n",
        "    return table_df\n",
        "\n",
        "# Function to run the analysis for client's tables 9, 10, 11, and 12\n",
        "def main_vsm_and_gbm(file_path):\n",
        "    # Load and preprocess data without and with emoticons\n",
        "    df_with_emoticons = load_and_preprocess_data(file_path, remove_emoticons=False)\n",
        "    df_without_emoticons = load_and_preprocess_data(file_path, remove_emoticons=True)\n",
        "\n",
        "    # Train and display Table 9\n",
        "    numeric_results = numeric_rating_prediction(df_without_emoticons)\n",
        "\n",
        "    # Train Random Forest using different V\n",
        "        # Train Random Forest using different VSM techniques (Table 10)\n",
        "    vsm_results = train_rf_with_vsm_techniques(df_without_emoticons)\n",
        "    print(\"\\nRandom Forest Results with Different VSM Techniques (Table 10):\")\n",
        "    print(tabulate(vsm_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Train Random Forest with and without emoticons (Table 11)\n",
        "    emoticon_results = train_rf_with_emoticons(df_with_emoticons, df_without_emoticons)\n",
        "    print(\"\\nRandom Forest Results with and without Emoticons (Table 11):\")\n",
        "    print(tabulate(emoticon_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Prepare data for Gradient Boosting (Table 12)\n",
        "    X_train, X_test, y_train, y_test = prepare_data_for_modeling(df_without_emoticons)\n",
        "\n",
        "    # Train Gradient Boosting with different learning rates (Table 12)\n",
        "    gbm_results = train_gbm_with_different_learning_rates(X_train, X_test, y_train, y_test)\n",
        "    print(\"\\nGradient Boosting Results with Different Learning Rates (Table 12):\")\n",
        "    print(tabulate(gbm_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Save all tables to CSV files\n",
        "    numeric_results.to_csv('numeric_rating_results.csv', index=False)\n",
        "    vsm_results.to_csv('rf_vsm_results.csv', index=False)\n",
        "    emoticon_results.to_csv('rf_emoticon_results.csv', index=False)\n",
        "    gbm_results.to_csv('gbm_learning_rate_results.csv', index=False)\n",
        "\n",
        "    print(\"\\nResults have been saved to 'numeric_rating_results.csv', 'rf_vsm_results.csv', 'rf_emoticon_results.csv', and 'gbm_learning_rate_results.csv'\")\n",
        "\n",
        "# Running the updated pipeline using the 'fitbit.csv' file as input\n",
        "if __name__ == \"__main__\":\n",
        "    main_vsm_and_gbm('/content/fitbit.csv')\n"
      ]
    }
  ]
}