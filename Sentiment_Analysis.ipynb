{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DLIWN4dxE0H2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKyYpirE9w3",
        "outputId": "7d541a24-93e6-4040-8156-bf3b712951ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path, remove_emoticons=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df[['review_description', 'rating']]\n",
        "    df['review_description'] = df['review_description'].astype(str)\n",
        "    df['cleaned_review'] = df['review_description'].apply(lambda x: clean_text(x, remove_emoticons))\n",
        "    df['sentiment'] = df['rating'].apply(label_sentiment)\n",
        "    return df"
      ],
      "metadata": {
        "id": "xi9xWKgGFCXf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text cleaning function with option to remove emoticons\n",
        "def clean_text(text, remove_emoticons=True):\n",
        "    if isinstance(text, str):\n",
        "        if remove_emoticons:\n",
        "            text = re.sub(r'[^\\w\\s]', '', text)  # Remove emoticons\n",
        "        text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove non-alphabetical characters\n",
        "        text = text.lower()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in text.split() if word not in stop_words]\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return ''"
      ],
      "metadata": {
        "id": "oV5U1Q7sFGOk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to label sentiment\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "# Prepare data for modeling\n",
        "def prepare_data_for_modeling(df):\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df['sentiment'])\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XRSham98FJni"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest using different VSM techniques\n",
        "def train_rf_with_vsm_techniques(df):\n",
        "    results = []\n",
        "\n",
        "    # TF-IDF Unigram\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF-IDF Bigrams\n",
        "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF(Bigram)', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF-IDF Trigrams\n",
        "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF(Trigram)', 'Accuracy': accuracy})\n",
        "\n",
        "    # TF (Term Frequency only)\n",
        "    vectorizer = CountVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF', 'Accuracy': accuracy})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Function to train Random Forest with and without emoticons\n",
        "def train_rf_with_emoticons(df_with_emoticons, df_without_emoticons):\n",
        "    results = []\n",
        "\n",
        "    # Run Random Forest with Emoticons\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df_with_emoticons['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df_with_emoticons['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF with Emoticons', 'Accuracy': accuracy})\n",
        "\n",
        "    # Run Random Forest without Emoticons\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df_without_emoticons['cleaned_review'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, df_without_emoticons['sentiment'], test_size=0.2, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results.append({'VSM Technique': 'TF/IDF without Emoticons', 'Accuracy': accuracy})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Train Gradient Boosting models with different learning rates\n",
        "def train_gbm_with_different_learning_rates(X_train, X_test, y_train, y_test):\n",
        "    learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "    results = []\n",
        "    for rate in learning_rates:\n",
        "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=rate, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results.append({'Learning Rate': rate, 'Accuracy': accuracy})\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Function to run the analysis for client's tables 10, 11, and 12\n",
        "def main_vsm_and_gbm(file_path):\n",
        "    # Load and preprocess data without and with emoticons\n",
        "    df_with_emoticons = load_and_preprocess_data(file_path, remove_emoticons=False)\n",
        "    df_without_emoticons = load_and_preprocess_data(file_path, remove_emoticons=True)\n",
        "\n",
        "    # Train Random Forest using different VSM techniques\n",
        "    vsm_results = train_rf_with_vsm_techniques(df_without_emoticons)\n",
        "    print(\"Random Forest Results with Different VSM Techniques:\")\n",
        "    print(tabulate(vsm_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Train Random Forest with and without emoticons\n",
        "    emoticon_results = train_rf_with_emoticons(df_with_emoticons, df_without_emoticons)\n",
        "    print(\"\\nRandom Forest Results with and without Emoticons:\")\n",
        "    print(tabulate(emoticon_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Train Gradient Boosting with different learning rates\n",
        "    X_train, X_test, y_train, y_test = prepare_data_for_modeling(df_without_emoticons)\n",
        "    gbm_results = train_gbm_with_different_learning_rates(X_train, X_test, y_train, y_test)\n",
        "    print(\"\\nGradient Boosting Results with Different Learning Rates:\")\n",
        "    print(tabulate(gbm_results, headers='keys', tablefmt='pipe', floatfmt='.4f'))\n",
        "\n",
        "    # Save results to CSV\n",
        "    vsm_results.to_csv('rf_vsm_results.csv', index=False)\n",
        "    emoticon_results.to_csv('rf_emoticon_results.csv', index=False)\n",
        "    gbm_results.to_csv('gbm_learning_rate_results.csv', index=False)\n",
        "    print(\"\\nResults have been saved to 'rf_vsm_results.csv', 'rf_emoticon_results.csv', and 'gbm_learning_rate_results.csv'\")\n",
        "\n",
        "# Running the updated pipeline\n",
        "# Running the updated pipeline using the 'fitbit.csv' file as input\n",
        "if __name__ == \"__main__\":\n",
        "    main_vsm_and_gbm('/content/fitbit.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7KoKClnFw2Y",
        "outputId": "e0712b95-88fd-487a-8ae4-a1d6f6693690"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Results with Different VSM Techniques:\n",
            "|    | VSM Technique   |   Accuracy |\n",
            "|---:|:----------------|-----------:|\n",
            "|  0 | TF/IDF          |     0.8171 |\n",
            "|  1 | TF/IDF(Bigram)  |     0.8166 |\n",
            "|  2 | TF/IDF(Trigram) |     0.8168 |\n",
            "|  3 | TF              |     0.8174 |\n",
            "\n",
            "Random Forest Results with and without Emoticons:\n",
            "|    | VSM Technique            |   Accuracy |\n",
            "|---:|:-------------------------|-----------:|\n",
            "|  0 | TF/IDF with Emoticons    |     0.8171 |\n",
            "|  1 | TF/IDF without Emoticons |     0.8171 |\n",
            "\n",
            "Gradient Boosting Results with Different Learning Rates:\n",
            "|    |   Learning Rate |   Accuracy |\n",
            "|---:|----------------:|-----------:|\n",
            "|  0 |          0.0500 |     0.7536 |\n",
            "|  1 |          0.1000 |     0.7752 |\n",
            "|  2 |          0.2500 |     0.7974 |\n",
            "|  3 |          0.5000 |     0.8078 |\n",
            "|  4 |          0.7500 |     0.8100 |\n",
            "|  5 |          1.0000 |     0.8115 |\n",
            "\n",
            "Results have been saved to 'rf_vsm_results.csv', 'rf_emoticon_results.csv', and 'gbm_learning_rate_results.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "itbkctq9UY2S"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}